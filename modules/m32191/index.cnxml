<document xmlns="http://cnx.rice.edu/cnxml" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:md="http://cnx.rice.edu/mdml">

<title>Practical 3 - Basic MPI</title>
<metadata>
  <md:content-id>m32191</md:content-id><md:title>Practical 3 - Basic MPI</md:title>
  <md:abstract>In this module you will gain some experience with the fundamentals of the MPI programming paradigm by executing some simple MPI codes through a series of simple exercises.</md:abstract>
  <md:uuid>cf2277bf-0d75-4821-93b5-e1ac4673e357</md:uuid>
</metadata>

<content>
  <section id="eip-387"><title>Introduction</title><para id="eip-547">In this practical you will develop and execute some simple codes, which incorporate the most fundamental MPI routines. Exercises include the querying of MPI ranks and size for a trivial MPI code, to the calculation of <term target-id="speedup">speedup</term> for computing <emphasis>pi</emphasis> in parallel. <newline count="2"/>If you require any assistance, please do not hesitate to contact the available support staff.
<newline count="2"/>
<note id="eip-id1170006429472"><label>Disclaimer</label>This course (and accompanying practical exercises) are not designed to teach you MPI programming but are provided to give you a feel for the MPI programming paradigm. A detailed introduction to MPI will be given in further courses that are under development.</note>
</para><section id="eip-922"><title>Objectives</title><para id="eip-611">The objectives of this practical are to gain experience in:
</para><list id="eip-365" list-type="enumerated" number-style="lower-roman"><item>executing a MPI code with different process counts</item>
<item>using basic MPI routines to query the <emphasis>size</emphasis> and <emphasis>rank</emphasis> of a MPI program</item>
<item>calculating <emphasis>speedup</emphasis> for a simple MPI program</item></list></section></section><section id="eip-184"><title>MPI: A Crash Course</title><para id="eip-95">MPI generally follows a <term target-id="spmd">Single Program Multiple Data</term> (SPMD) programming model, whereby a single executable (called a <emphasis>process</emphasis>) is duplicated and executed on multiple processors. Each process (within the <term target-id="MPIworld">MPI Communication World</term>) is uniquely identified by its <term target-id="rank">rank</term> and individual processes can communicate between each other using MPI <term target-id="messagePassing">message-passing</term> routines.
</para><note id="eip-693" type="note">MPI can also accommodate a Multiple Programming Multiple Data (MPMD) programming paradigm (where each process is a different executable) but this approach is less used (and supported) compared to the SPMD approach. </note><para id="eip-732">Figure 1 shows a typical MPI communication world (initially referred to as <emphasis>MPI_COMM_WORLD</emphasis>) with 4 processes (labeled <emphasis>P</emphasis>) each identified with a unique rank in the range 0-3. Each process executes the same task <emphasis>T</emphasis>. Processes communicate among other processes in the communication world by <emphasis>sending</emphasis> and <emphasis>receiving</emphasis> messages.</para><figure id="MPI"><media id="mpiPNG" alt="MPI Communication World">
    <image height="350" mime-type="image/jpeg" src="../../media/MPI.jpg"/>
  </media>
  
<caption>The Standard MPI Communication World
  </caption></figure><note id="eip-830" type="tip"><label>MPI Info</label>Even though each process contains an instance of the same executable, different instruction streams can be executed by embedding rank dependent code into the executable e.g.<code id="eip-268" display="block">if (myrank .eq. 0) then
  call do_this_work_on_process_0()
else if (myrank .eq. 1) then
  call do_this_work_on_process_1()
else
  call do_this_work_on_remaining_processes()
end if</code></note><para id="eip-156">The most fundamental MPI operations can be classified into 3 groups: </para><list id="eip-273" list-type="enumerated" number-style="arabic"><item>MPI Initialization and Finalization
<list id="eip-id12861666" list-type="labeled-item"><item><label>Initialization</label>MPI_Init()</item>
<item><label>Finalization</label>MPI_Finalize()</item></list></item>
<item>Querying Process Rank and Communication World Size<list id="eip-id18840598" list-type="labeled-item"><item><label>Query Process Rank</label>MPI_Comm_rank()</item>
<item><label>Query World Size</label>MPI_Comm_size()</item></list></item>
<item>Sending and Receiving of Messages<list id="eip-id18775054" list-type="labeled-item"><item><label>Send Message</label>MPI_Send()</item>
<item><label>Receive Message</label>MPI_Receive()</item></list></item></list><note id="eip-385">For more detailed information on MPI, download and review the latest MPI standard <link resource="mp21_spec.pdf">specification</link>.</note></section><section id="eip-305"><title>Basic MPI: "Hello World"</title><exercise id="eip-336"><title>Executing A Simple MPI Code</title><problem id="eip-676">
  <para id="eip-173">Develop, compile and execute a code (which uses the MPI framework) to display a "Hello World" message on multiple processes. Test your MPI code works correctly for 1, 2 4 and 8 cores.
<note id="eip-id1170714766181"><label>Code Tip</label>If you are not brave enough (yet) to write the code, you can use the MPI template provided in the <emphasis>../Practicals/Practical_3/Exercise_1</emphasis> folder.</note><note id="eip-id17196077"><label>Batch Script Tip</label>Make sure you modify your submission script to request multiple processes and cores in your job e.g. to test your code for 8 processes modify your script to contain the following:
<code id="eip-id17060717" display="block">...
#PBS -l mppwidth=8        # Request 8 cores
...
...
aprun -n 8 ./hello_world  # Request 8 processes</code></note></para>
</problem></exercise><exercise id="eip-354"><title>Querying MPI Rank and Size </title><problem id="eip-235">
  <para id="eip-69">Modify your solution in Exercise 1 to print the "Hello World" message, along with the rank of the current process and the total number of processes in the MPI communication world. 
  </para>
</problem>

<solution id="eip-945">
<label>Hint</label>
  <para id="eip-848">Use the <emphasis>MPI_COMM_RANK()</emphasis> and <emphasis>MPI_COMM_SIZE()</emphasis> routines to find the rank of the current process and the size of the communication world, respectively.
  </para>
</solution>

<solution id="eip-id11020461">
<label>Fortran Solution</label>
<code id="eip-id18208480" display="block">
...
! Initialize MPI
call MPI_INIT(error) 
 
call MPI_COMM_RANK(MPI_COMM_WORLD,myrank,error) 
call MPI_COMM_SIZE(MPI_COMM_WORLD,np,error)
print *, 'Hello World! I am process', myrank, ' of ', np 
  
! Shut down MPI 
call MPI_FINALIZE(error)
... 
</code>
</solution>
<solution id="fs-id4080789">
<label>C Solution</label>
<code id="fs-id13776026" display="block">...
MPI_Init(&amp;argc,&amp;argv);

MPI_Comm_size(MPI_COMM_WORLD,&amp;np);
MPI_Comm_rank(MPI_COMM_WORLD,&amp;myrank);

printf("Hello World! I am process %d of %d\n", myrank, np);

MPI_Finalize();
... 
</code>
</solution>
</exercise></section><section id="eip-388"><title>Measuring Speedup</title><para id="eip-704">In parallel computing, <term target-id="speedup">speedup</term> refers to how much a parallel algorithm is faster than a corresponding sequential algorithm. <newline count="2"/>Speedup is defined as:<newline count="2"/>
<space count="40"/><m:math>
<m:apply>
  <m:eq/>
  <m:ci>
    <m:msub>
      <m:mi>S</m:mi>
      <m:mi>p</m:mi>
    </m:msub>
  </m:ci>
  <m:apply>
    <m:divide/>
    <m:ci>
      <m:msub>
        <m:mi>T</m:mi>
        <m:mi>1</m:mi>
      </m:msub>
    </m:ci>
    <m:ci>
      <m:msub>
        <m:mi>T</m:mi>
        <m:mi>p</m:mi>
      </m:msub>
    </m:ci>
  </m:apply>
</m:apply>
</m:math></para><para id="eip-479">where</para><list id="eip-687"><item><emphasis>p</emphasis> is the number of processers</item>
<item><emphasis><m:math>
<m:ci>
  <m:msub>
    <m:mi>T</m:mi>
    <m:mi>1</m:mi>
  </m:msub>
</m:ci>
</m:math></emphasis> is the time of the sequential algorithm</item>
<item><emphasis><m:math>
<m:ci>
  <m:msub>
    <m:mi>T</m:mi>
    <m:mi>p</m:mi>
  </m:msub>
</m:ci>
</m:math></emphasis> is the time of the parallel algorithm with <emphasis>p</emphasis> processors</item></list><exercise id="eip-747"><title>Calculating PI</title><problem id="eip-159">
  <para id="eip-145">The value of <emphasis>pi</emphasis> can be computed approximately using an integration technique (see the course <link resource="HPC_Intro.pdf">slides</link> for more information). Using the serial and parallel code implementations found in ../Practicals/Practical_3/Exercise_2, calculate the speedup obtained for 1, 2, 4 and 8 processors.
<note id="eip-id5001162"><label>Tip</label>Briefly review the serial and parallel code implementations so you are familiar with the computational method and its MPI parallelisaton.</note></para>
<para id="eip-id1167077468273">Record your results in a table similar to Table 1.</para>
</problem>
</exercise><table id="eip-491" summary="Table of Speedup Results for Ï€ Calculation">
<tgroup cols="3"><tbody>
  <row>
    <entry>Processors</entry>
    <entry>Time Taken(sec)</entry>
    <entry>Speedup</entry>
  </row>
  <row>
    <entry><space count="3"/>1</entry>
    <entry/>
    <entry/>
  </row>
  <row>
    <entry><space count="3"/>2</entry>
    <entry/>
    <entry/>
  </row>
  <row>
    <entry><space count="3"/>4</entry>
    <entry/>
    <entry/>
  </row>
  <row>
    <entry><space count="3"/>8</entry>
    <entry/>
    <entry/>
  </row>
</tbody>

</tgroup><caption>Speedup Results for PI Calculation</caption>
</table></section>
</content>

<glossary>

<definition id="messagePassing">
<term>Message Passing</term>
<meaning id="fs-id1164004841492"><para id="fs-id1164007068516">A communication protocol whereby processes communicate by sending and receiving data through messages.</para>
</meaning>
</definition>

<definition id="MPIworld">
<term>MPI Communication World</term>
<meaning id="fs-id1171882614640"><para id="fs-id1171894623374">A collection of MPI processes which can communicate through passing messages. The default communication world for a MPI process is <emphasis>MPI_COMM_WORLD</emphasis></para>
</meaning>
</definition>

<definition id="rank">
<term>MPI Rank</term>
<meaning id="fs-id1169581562099"><para id="fs-id1169567921250">Each process in a MPI communication world of <emphasis>P</emphasis> processes is assigned an unique id in the range 0..(P-1). This id is called the <emphasis>rank</emphasis> of the process.</para>
</meaning>
</definition>

<definition id="speedup">
<term>Speedup</term>
<meaning id="fs-id7366140"><para id="fs-id16462636">In parallel computing, <emphasis>speedup</emphasis> refers to how much a parallel algorithm is faster than a corresponding sequential algorithm.</para>
<figure id="speedupFig">
<media id="speedupPhoto" alt="Speedup Diagram">
      <image width="300" mime-type="image/png" src="../../media/Speedup.png"/>
</media>
<caption>Speedup Diagram</caption></figure>
</meaning>
</definition>

<definition id="spmd">
<term>SPMD</term>
<meaning id="fs-id8433378"><para id="fs-id8850206">Single Program Multiple Data: multiple autonomous processors simultaneously execute the same program at independent points.<newline/><newline/>Further information: <link url="http://en.wikipedia.org/wiki/SPMD" window="new">http://en.wikipedia.org/wiki/SPMD</link></para>
</meaning>
</definition>

</glossary>

</document>